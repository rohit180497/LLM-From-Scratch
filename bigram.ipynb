{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7305da92-cc9b-4a3c-9fb8-fb81deca3c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2b958f-f9d9-4312-82fe-8ce4cdd150ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230467\n"
     ]
    }
   ],
   "source": [
    "with open (\"wizard_of_oz.txt\", 'r', encoding = 'utf8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa3f2a7-f93b-43ca-a17b-d200869090f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Dorothy and the Wizard in Oz\n",
      "\n",
      "\n",
      "  A Faithful Record of Their Amazing Adventures\n",
      "    in an Underground World; and How with the\n",
      "     Aid of Their Friends Zeb Hugson, Eureka\n",
      "       the Kitten, and Jim the\n"
     ]
    }
   ],
   "source": [
    "print(text[:201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "960a88b7-cc5d-4ffe-b0a6-81f7f02b3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c1f1aa-a704-4a1a-8fa2-8b46dcd26b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(chars))\n",
    "chars[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df74ba8-96ec-4b9c-b378-58e276e0c2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 53, 60, 60, 63]\n",
      "Hello\n"
     ]
    }
   ],
   "source": [
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "encoded_hello = encode(\"Hello\")\n",
    "decoded_hello = decode(encoded_hello)\n",
    "print(encoded_hello)\n",
    "print(decoded_hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05e02228-177e-4ef4-9caf-78901ab8ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([75, 27, 63, 66, 63, 68, 56, 73,  1, 49, 62, 52,  1, 68, 56, 53,  1, 46,\n",
      "        57, 74, 49, 66, 52,  1, 57, 62,  1, 38, 74,  0,  0,  0,  1,  1, 24,  1,\n",
      "        29, 49, 57, 68, 56, 54, 69, 60,  1, 41, 53, 51, 63, 66, 52,  1, 63, 54,\n",
      "         1, 43, 56, 53, 57, 66,  1, 24, 61, 49, 74, 57, 62, 55,  1, 24, 52, 70,\n",
      "        53, 62, 68, 69, 66, 53, 67,  0,  1,  1,  1,  1, 57, 62,  1, 49, 62,  1,\n",
      "        44, 62, 52, 53, 66, 55, 66, 63, 69, 62])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(data[: 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "660a8b86-212c-45e1-90c0-eb52d2b92191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is  tensor([75]) target is tensor(27)\n",
      "when input is  tensor([75, 27]) target is tensor(63)\n",
      "when input is  tensor([75, 27, 63]) target is tensor(66)\n",
      "when input is  tensor([75, 27, 63, 66]) target is tensor(63)\n",
      "when input is  tensor([75, 27, 63, 66, 63]) target is tensor(68)\n",
      "when input is  tensor([75, 27, 63, 66, 63, 68]) target is tensor(56)\n",
      "when input is  tensor([75, 27, 63, 66, 63, 68, 56]) target is tensor(73)\n",
      "when input is  tensor([75, 27, 63, 66, 63, 68, 56, 73]) target is tensor(1)\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size = 8\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(\"when input is \", context, \"target is\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "500bfced-ed49-4283-bcea-49a9e641e913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "tensor1 = torch.tensor([1,2,3])\n",
    "tensor2 = torch.tensor([4,5,6])\n",
    "tensor3 = torch.tensor([7,8,9])\n",
    "\n",
    "stack_tensor = torch.stack([tensor1, tensor2, tensor3])\n",
    "print(stack_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d650875-dc92-4ce2-bf0f-1fef10b9d544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.3913,  -3.6933,   8.6864], grad_fn=<SqueezeBackward4>)\n",
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "sample = torch.tensor([10.,10.,10.])\n",
    "linear = nn.Linear(3,3 , bias= False)\n",
    "print(linear(sample))\n",
    "\n",
    "import torch.nn.functional as F\n",
    "# Create a tensor\n",
    "tensor1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "# Apply softmax using torch.nn.functional.softmax()\n",
    "softmax_output = F.softmax(tensor1, dim=0)\n",
    "print(softmax_output)\n",
    "\n",
    "# Watch tutorial video for softmax explaination\n",
    "# read more here: https://pytorch.org/docs/stable/nn.html\n",
    "# read more about it here: https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b47dc50-c443-4f82-af10-a5425576700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[71, 49, 67,  1, 67, 63,  1, 49],\n",
      "        [69, 64,  1, 71, 57, 68, 56,  1],\n",
      "        [67, 71, 53, 66, 53, 52,  1, 68],\n",
      "        [69, 66, 57, 53, 67,  1, 49, 55]])\n",
      "targets:\n",
      "tensor([[49, 67,  1, 67, 63,  1, 49, 67],\n",
      "        [64,  1, 71, 57, 68, 56,  1, 49],\n",
      "        [71, 53, 66, 53, 52,  1, 68, 56],\n",
      "        [66, 57, 53, 67,  1, 49, 55, 63]])\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size = 8 #The length of each sequence (or \"block\") of data to be processed by the model\n",
    "batch_size = 4 #The number of such sequences processed in one forward and backward pass (i.e., in parallel).\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "# print(x.shape)\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a203074f-cf97-4a23-a97a-511e8ab6c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 10000\n",
    "learning_rate = 3e-4\n",
    "vocab_size = len(chars)\n",
    "eval_iters = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8108347-f936-40b0-969d-57f58b491d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ec7ce3c-ad18-4d74-865f-d9c5200a9b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VD;wc6Fksc6GnkD-E)VxekbIG)GxErYQ\"b5 SUWtw0glsI&&! 52m)hwN8﻿rPz5aIj4&cgU5coMJeSO\n",
      "..&KQP:HRSs99Z'Z)5VNUW68Oz(7t2b (6E5!LZGKMIaPw!7e\n",
      "sUC67D\n",
      "5\n",
      "ys'Y:ITeHb0uHYQsc6N8G i4v3'nYyq2MJ5jE3,)1&41&oR'jI5vjIA8K02nPN?qW7W(ojEvFt-MJei)N&sTdLE;ZqP2FAhV;Qsc6Ssx3m(plCaOl\n",
      "KsW0&cnJ 5y7'eWCP1MTjcHksBp89(u??I!Q1&jTcj\"mT4,DQPe8aC4vP)vEKM5iemf'kTYq﻿c5i2-9 55I\n",
      "'ZJDJqWc0MJ.d!KMB2mI﻿NPCQ&iU6gLN'eqF1MOS3qnmk5 (8i﻿6VRPnJwNZRv'Y2rrDFO\n",
      "lpQo-2-OB&6Kt;:TA!fxcg\"\n",
      "e-i4u6Sh5fEcl7W(hW3N02ps.\"koJ\n",
      "5(7?qfoe0:﻿sF!yx(9c:CL&'bkzLrAT?.k2J)o\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)  #This creates an embedding layer. It maps each token (word) in the vocabulary to a vector of size vocab_size\n",
    "        \n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape  #Batch size, sequence length, and number of classes (vocab size) respectively.\n",
    "            logits = logits.view(B*T, C) #Reshapes the logits tensor to be of shape (B*T, C) for computing cross-entropy loss.\n",
    "            targets = targets.view(B*T)  #Reshapes the targets tensor to match the shape required by F.cross_entropy.\n",
    "            loss = F.cross_entropy(logits, targets)  #Computes the cross-entropy loss between the logits and the targets.\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a76ad94a-0209-4a04-9424-fc11f84f612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 3.153, val loss: 3.158\n",
      "step: 250, train loss: 3.104, val loss: 3.152\n",
      "step: 500, train loss: 3.078, val loss: 3.157\n",
      "step: 750, train loss: 3.099, val loss: 3.098\n",
      "step: 1000, train loss: 3.035, val loss: 3.077\n",
      "step: 1250, train loss: 3.016, val loss: 3.036\n",
      "step: 1500, train loss: 3.016, val loss: 3.045\n",
      "step: 1750, train loss: 2.972, val loss: 3.024\n",
      "step: 2000, train loss: 2.969, val loss: 3.010\n",
      "step: 2250, train loss: 2.942, val loss: 3.008\n",
      "step: 2500, train loss: 2.938, val loss: 2.945\n",
      "step: 2750, train loss: 2.909, val loss: 2.964\n",
      "step: 3000, train loss: 2.902, val loss: 2.935\n",
      "step: 3250, train loss: 2.909, val loss: 2.925\n",
      "step: 3500, train loss: 2.851, val loss: 2.906\n",
      "step: 3750, train loss: 2.866, val loss: 2.880\n",
      "step: 4000, train loss: 2.848, val loss: 2.897\n",
      "step: 4250, train loss: 2.840, val loss: 2.866\n",
      "step: 4500, train loss: 2.830, val loss: 2.850\n",
      "step: 4750, train loss: 2.818, val loss: 2.860\n",
      "step: 5000, train loss: 2.760, val loss: 2.860\n",
      "step: 5250, train loss: 2.775, val loss: 2.809\n",
      "step: 5500, train loss: 2.771, val loss: 2.809\n",
      "step: 5750, train loss: 2.768, val loss: 2.777\n",
      "step: 6000, train loss: 2.757, val loss: 2.798\n",
      "step: 6250, train loss: 2.719, val loss: 2.772\n",
      "step: 6500, train loss: 2.733, val loss: 2.793\n",
      "step: 6750, train loss: 2.721, val loss: 2.778\n",
      "step: 7000, train loss: 2.687, val loss: 2.748\n",
      "step: 7250, train loss: 2.690, val loss: 2.741\n",
      "step: 7500, train loss: 2.691, val loss: 2.742\n",
      "step: 7750, train loss: 2.701, val loss: 2.706\n",
      "step: 8000, train loss: 2.701, val loss: 2.743\n",
      "step: 8250, train loss: 2.677, val loss: 2.725\n",
      "step: 8500, train loss: 2.677, val loss: 2.704\n",
      "step: 8750, train loss: 2.688, val loss: 2.704\n",
      "step: 9000, train loss: 2.688, val loss: 2.678\n",
      "step: 9250, train loss: 2.642, val loss: 2.676\n",
      "step: 9500, train loss: 2.619, val loss: 2.641\n",
      "step: 9750, train loss: 2.638, val loss: 2.711\n",
      "2.7023065090179443\n"
     ]
    }
   ],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# A variant of the Adam optimizer that includes weight decay to improve generalization.\n",
    "\n",
    "for iter in range(max_iters): #Loops over the training process for a specified number of iterations (max_iters).\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss() \n",
    "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train') \n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb) #Calls the forward method of the model (which is equivalent to model(xb, yb) in PyTorch) to compute the predictions (logits) and the loss for the current batch.\n",
    "    optimizer.zero_grad(set_to_none=True) #Resets the gradients of all the model parameters to zero before the backward pass.\n",
    "    loss.backward() #Computes the gradients of the loss with respect to the model parameters using backpropagation.\n",
    "    optimizer.step() #Updates the model parameters using the computed gradients based on the optimization algorithm (AdamW in this case).\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1fcb9f-1a98-44c5-a6be-75bae6fd0ba1",
   "metadata": {},
   "source": [
    "need to familiarize audience with optimizers (AdamW, Adam, SGD, MSE…) no need to jump into the formulas, just what the optimizer does for us and some of the differences/similarities between them\n",
    "\n",
    "Mean Squared Error (MSE): MSE is a common loss function used in regression problems, where the goal is to predict a continuous output. It measures the average squared difference between the predicted and actual values, and is often used to train neural networks for regression tasks.\n",
    "\n",
    "Gradient Descent (GD): is an optimization algorithm used to minimize the loss function of a machine learning model. The loss function measures how well the model is able to predict the target variable based on the input features. The idea of GD is to iteratively adjust the model parameters in the direction of the steepest descent of the loss function\n",
    "\n",
    "Momentum: Momentum is an extension of SGD that adds a \"momentum\" term to the parameter updates. This term helps smooth out the updates and allows the optimizer to continue moving in the right direction, even if the gradient changes direction or varies in magnitude. Momentum is particularly useful for training deep neural networks.\n",
    "\n",
    "RMSprop: RMSprop is an optimization algorithm that uses a moving average of the squared gradient to adapt the learning rate of each parameter. This helps to avoid oscillations in the parameter updates and can improve convergence in some cases.\n",
    "\n",
    "Adam: Adam is a popular optimization algorithm that combines the ideas of momentum and RMSprop. It uses a moving average of both the gradient and its squared value to adapt the learning rate of each parameter. Adam is often used as a default optimizer for deep learning models.\n",
    "\n",
    "AdamW: AdamW is a modification of the Adam optimizer that adds weight decay to the parameter updates. This helps to regularize the model and can improve generalization performance. We will be using the AdamW optimizer as it best suits the properties of the model we will train in this video.\n",
    "find more optimizers and details at torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "015222ea-0e17-42a3-8958-3bd1b1246ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "f  DKedy rengyW:u(Yu0D,\"tb, temiscln,\n",
      "igy aind ff(o  2d arl wenthecy,\" Wel;W8'm ff Clll,\"87SithevGb,,:Ag;(B(hewithenthac. shthe all! l v5tcav?gleve, D\n",
      "se mY!RVRDo er t\n",
      "dind s leancenchathe th W3vedensir ntalle angeauntofz.Lrrfye&s an ar,\n",
      "Jr w Ixed Clyom&V1z?myothed satayWin asTaru\n",
      "\"Cind2 shesle,\"\n",
      "\n",
      "bla:qv5osar47stowase\n",
      "\"The f t dPP-bblonenebre bethiapp tN29UhconcCe t\n",
      "jt are \"1xz;ke\n",
      "ge gixand peak. o bvillsord ale'k tha stt ingTBplJ0ch thte'd T. andem k(o?\"I5y an tincl acito,,\"DFg Ievw ar\n",
      "F)ZGm t-\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "056ed019-91d5-40dd-a300-8507ec1d4e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4875])\n"
     ]
    }
   ],
   "source": [
    "### Activation Functions\n",
    "\n",
    "x = torch.tensor([-0.05], dtype= torch.float32)\n",
    "y = F.sigmoid(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5fbcddf-8500-4252-a382-649b2aa5c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7114])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([0.89], dtype= torch.float32)\n",
    "y = F.tanh(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "60e21f8d-699c-4eb7-a060-9cb45dcfdf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 20.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([10, 20], dtype= torch.float32)\n",
    "y = F.relu(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771dddf-7982-4c10-be26-8a7e7575e5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
